{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ad5c5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BlipProcessor, BlipForConditionalGeneration, BlipForQuestionAnswering\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57fb8cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_multimodal_model(save_directory=\"./blip_model\"):\n",
    "    os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "    processor = BlipProcessor.from_pretrained(\"Salesforce/blip-vqa-base\")\n",
    "    model = BlipForQuestionAnswering.from_pretrained(\"Salesforce/blip-vqa-base\")\n",
    "\n",
    "    processor_path = os.path.join(save_directory, \"processor\")\n",
    "    model_path = os.path.join(save_directory, \"model\")\n",
    "\n",
    "    processor.save_pretrained(processor_path)\n",
    "    model.save_pretrained(model_path)   \n",
    "\n",
    "    print(f\"Model and processor saved to {save_directory}\")\n",
    "\n",
    "    for root, dirs, files in os.walk(save_directory):\n",
    "        for file in files:\n",
    "            print(f\"{os.path.relpath(os.path.join(root, file), save_directory)}\")\n",
    "\n",
    "    return save_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a63d64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81c64b09ed5d45cdaf411f9cc5170662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/445 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a78d4c96cd7a46be97110c06d9eb3bce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/592 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85a5224f358842f8a3454d76b10238d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0317ab34c6c74b92ade3c06d8633a618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e3f0c38cc9d427998bfd7eff7ff5414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2180ea412e594507bab9597312f4db3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1da0e17d93d04e889a2cc0e3186cd527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs.hf.co/repos/aa/ad/aaad7f73f20d7afb48036bd3013cc2ba3c6d79f49861c892725ac44fe5e081be/33786eed34def0c95fa948128cb4386be9b9219aa2c2e25f1c9c744692121bb7?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1753982832&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1Mzk4MjgzMn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy9hYS9hZC9hYWFkN2Y3M2YyMGQ3YWZiNDgwMzZiZDMwMTNjYzJiYTNjNmQ3OWY0OTg2MWM4OTI3MjVhYzQ0ZmU1ZTA4MWJlLzMzNzg2ZWVkMzRkZWYwYzk1ZmE5NDgxMjhjYjQzODZiZTliOTIxOWFhMmMyZTI1ZjFjOWM3NDQ2OTIxMjFiYjc%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=W6ygJIAUKilrwjegXRt2-do2kcGN-IRjoV9ZPIrWP-g84%7EDKAZeMQYetNEwgpgW5ZHIt7wm1NrWHiYHDGa2-XZQn5HIE9IGQigtW5iKWdxJpbpj24YsG5ze4rzqENqg4czlLPXI1wBwqLZ8AlnxZaP4fgzioX71%7EKT-X%7EYj8-ZU4Ar-7MMcgU%7ErQ%7EQtnguuaRA3eeMoFQ9yBt%7EPesADPQ0ecA5pRittPZWVxrr1bGsh2WW%7Eoeuplf6ffAdsGkDMogSI0zjCs2mu87mrjqJ9PZOA9ImgO7Iqx20dR8EKGv-jDCBOSemwqfhXC-Byxv9dtz5oAPKJQYSEAVe2Wdlztuw__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c20d01b95c6840a9a661bc10fbdbf40d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  15%|#4        | 231M/1.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and processor saved to ./blip_model\n",
      "processor/tokenizer_config.json\n",
      "processor/special_tokens_map.json\n",
      "processor/tokenizer.json\n",
      "processor/vocab.txt\n",
      "processor/preprocessor_config.json\n",
      "model/model.safetensors\n",
      "model/config.json\n",
      "model/generation_config.json\n",
      "\n",
      " Model downloaded to ./blip_model\n"
     ]
    }
   ],
   "source": [
    "model_directory = download_multimodal_model()\n",
    "print(f\"\\n Model downloaded to {model_directory}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "576bee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import base64\n",
    "import io\n",
    "import requests\n",
    "\n",
    "processor = BlipProcessor.from_pretrained(\"./blip_model/processor\")\n",
    "model = BlipForQuestionAnswering.from_pretrained(\"./blip_model/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcad12a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_about_image(image_path, question):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    \n",
    "    inputs = processor(images=image, text=question, return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs)\n",
    "    \n",
    "    answer = processor.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {answer}\")\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b1ec313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is in this image?\n",
      "Answer: food\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'food'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_about_image(image_path=\"spagetthi.jpeg\", question=\"What is in this image?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "840253fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is in this image? You should give me a detailed answer.\n",
      "Answer: name\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'name'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_about_image(image_path=\"friend.jpeg\", question=\"What is in this image? You should give me a detailed answer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098c87c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
